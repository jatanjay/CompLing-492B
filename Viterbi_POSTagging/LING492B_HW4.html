<!doctype html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<style>
body {
	font-family: Verdana, Geneva, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  padding-top: 10px;
  padding-bottom: 10px;
  background-color: white;
  padding: 30px; }

body > *:first-child {
  margin-top: 0 !important; }
body > *:last-child {
  margin-bottom: 0 !important; }

a {
  color: #4183C4; }
a.absent {
  color: #cc0000; }
a.anchor {
  display: block;
  padding-left: 30px;
  margin-left: -30px;
  cursor: pointer;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0; }

h1, h2, h3, h4, h5, h6 {
	font-family: Verdana, Geneva, sans-serif;
	margin: 20px 0 10px;
  	padding: 0;
  	font-weight: bold;
  	-webkit-font-smoothing: antialiased;
  	cursor: text;
  	position: relative; }

h1:hover a.anchor, h2:hover a.anchor, h3:hover a.anchor, h4:hover a.anchor, h5:hover a.anchor, h6:hover a.anchor {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA09pVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMy1jMDExIDY2LjE0NTY2MSwgMjAxMi8wMi8wNi0xNDo1NjoyNyAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNiAoMTMuMCAyMDEyMDMwNS5tLjQxNSAyMDEyLzAzLzA1OjIxOjAwOjAwKSAgKE1hY2ludG9zaCkiIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OUM2NjlDQjI4ODBGMTFFMTg1ODlEODNERDJBRjUwQTQiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OUM2NjlDQjM4ODBGMTFFMTg1ODlEODNERDJBRjUwQTQiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo5QzY2OUNCMDg4MEYxMUUxODU4OUQ4M0REMkFGNTBBNCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo5QzY2OUNCMTg4MEYxMUUxODU4OUQ4M0REMkFGNTBBNCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PsQhXeAAAABfSURBVHjaYvz//z8DJYCRUgMYQAbAMBQIAvEqkBQWXI6sHqwHiwG70TTBxGaiWwjCTGgOUgJiF1J8wMRAIUA34B4Q76HUBelAfJYSA0CuMIEaRP8wGIkGMA54bgQIMACAmkXJi0hKJQAAAABJRU5ErkJggg==) no-repeat 10px center;
  text-decoration: none; }

h1 tt, h1 code {
  font-size: inherit; }

h2 tt, h2 code {
  font-size: inherit; }

h3 tt, h3 code {
  font-size: inherit; }

h4 tt, h4 code {
  font-size: inherit; }

h5 tt, h5 code {
  font-size: inherit; }

h6 tt, h6 code {
  font-size: inherit; }

h1 {
	font-size: 28px;
    border: 3px solid #892034; 
    color: black;
	text-align:right;
}

h2 {
	font-size: 24px;
	background-color:#892034; 
    color: white; 
}

h3 {
	font-size: 18px;
    border-bottom: 1px solid #892034;
	color: black; 
}

h4 {
  font-size: 16px; }

h5 {
  font-size: 14px; }

h6 {
  color: #777777;
  font-size: 14px; }

p, blockquote, ul, ol, dl, li, table, pre {
  margin: 15px 0; }

hr {
  background: transparent url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAYAAAAECAYAAACtBE5DAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAyJpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNSBNYWNpbnRvc2giIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OENDRjNBN0E2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OENDRjNBN0I2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo4Q0NGM0E3ODY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo4Q0NGM0E3OTY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PqqezsUAAAAfSURBVHjaYmRABcYwBiM2QSA4y4hNEKYDQxAEAAIMAHNGAzhkPOlYAAAAAElFTkSuQmCC) repeat-x 0 0;
  border: 0 none;
  color: #cccccc;
  height: 4px;
  padding: 0;
}

body > h2:first-child {
  margin-top: 0;
  padding-top: 0; }
body > h1:first-child {
  margin-top: 0;
  padding-top: 0; }
  body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0; }
body > h3:first-child, body > h4:first-child, body > h5:first-child, body > h6:first-child {
  margin-top: 0;
  padding-top: 0; }

a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 {
  margin-top: 0;
  padding-top: 0; }

h1 p, h2 p, h3 p, h4 p, h5 p, h6 p {
  margin-top: 0; }

li p.first {
  display: inline-block; }
li {
  margin: 0; }
ul, ol {
  padding-left: 30px; }

ul :first-child, ol :first-child {
  margin-top: 0; }

dl {
  padding: 0; }
  dl dt {
    font-size: 14px;
    font-weight: bold;
    font-style: italic;
    padding: 0;
    margin: 15px 0 5px; }
    dl dt:first-child {
      padding: 0; }
    dl dt > :first-child {
      margin-top: 0; }
    dl dt > :last-child {
      margin-bottom: 0; }
  dl dd {
    margin: 0 0 15px;
    padding: 0 15px; }
    dl dd > :first-child {
      margin-top: 0; }
    dl dd > :last-child {
      margin-bottom: 0; }

blockquote {
  border-left: 4px solid #dddddd;
  padding: 0 15px;
  color: #777777; }
  blockquote > :first-child {
    margin-top: 0; }
  blockquote > :last-child {
    margin-bottom: 0; }

table {
  padding: 0;border-collapse: collapse; }
  table tr {
    border-top: 1px solid #cccccc;
    background-color: white;
    margin: 0;
    padding: 0; }
    table tr:nth-child(2n) {
      background-color: #f8f8f8; }
    table tr th {
      font-weight: bold;
      border: 1px solid #cccccc;
      margin: 0;
      padding: 6px 13px; }
    table tr td {
      border: 1px solid #cccccc;
      margin: 0;
      padding: 6px 13px; }
    table tr th :first-child, table tr td :first-child {
      margin-top: 0; }
    table tr th :last-child, table tr td :last-child {
      margin-bottom: 0; }

img {
  max-width: 100%; }

span.frame {
  display: block;
  overflow: hidden; }
  span.frame > span {
    border: 1px solid #dddddd;
    display: block;
    float: left;
    overflow: hidden;
    margin: 13px 0 0;
    padding: 7px;
    width: auto; }
  span.frame span img {
    display: block;
    float: left; }
  span.frame span span {
    clear: both;
    color: #333333;
    display: block;
    padding: 5px 0 0; }
span.align-center {
  display: block;
  overflow: hidden;
  clear: both; }
  span.align-center > span {
    display: block;
    overflow: hidden;
    margin: 13px auto 0;
    text-align: center; }
  span.align-center span img {
    margin: 0 auto;
    text-align: center; }
span.align-right {
  display: block;
  overflow: hidden;
  clear: both; }
  span.align-right > span {
    display: block;
    overflow: hidden;
    margin: 13px 0 0;
    text-align: right; }
  span.align-right span img {
    margin: 0;
    text-align: right; }
span.float-left {
  display: block;
  margin-right: 13px;
  overflow: hidden;
  float: left; }
  span.float-left span {
    margin: 13px 0 0; }
span.float-right {
  display: block;
  margin-left: 13px;
  overflow: hidden;
  float: right; }
  span.float-right > span {
    display: block;
    overflow: hidden;
    margin: 13px auto 0;
    text-align: right; }

code, tt {
  margin: 0 2px;
  padding: 0 5px;
  white-space: nowrap;
  border: 1px solid #eaeaea;
  background-color: #f8f8f8;
  border-radius: 3px; 
}

pre code {
  margin: 0;
  padding: 0;
  white-space: pre;
  border: none;
  background: transparent; }

.highlight pre {
  background-color: #f8f8f8;
  border: 1px solid #cccccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px; }

pre {
  background-color: #f8f8f8;
  border: 1px solid #cccccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px; }
  pre code, pre tt {
    background-color: transparent;
    border: none; }

sup {
    font-size: 0.83em;
    vertical-align: super;
    line-height: 0;
}
* {
	-webkit-print-color-adjust: exact;
}
@media screen and (min-width: 914px) {
    body {
        width: 854px;
        margin:0 auto;
    }
}

@media print {
	table, pre {
		page-break-inside: avoid;
	}
	pre {
		word-wrap: break-word;
	}
}

   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: rgb(88, 72, 246)
   }

   pre .number {
     color: rgb(0, 0, 205);
   }

   pre .comment {
     color: rgb(76, 136, 107);
   }

   pre .keyword {
     color: rgb(0, 0, 255);
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: rgb(3, 106, 7);
   }


</style>
<title>LINGUIST492B: Homework #4</title>
<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax:{inlineMath:[['$$$','$$$']]}});</script><script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
<h1>LINGUIST492B: Homework #4</h1>

<h2>POS Tagging with an HMM</h2>

<p>In this assignment, you will implement the Forward Procedure and the the Viterbi Algorithm for Hidden Markov Models. Your task is to analyze the sentence:</p>

<pre><code>"time flies quickly"
</code></pre>

<p>Using a Hidden Markov Model part of speech tagger. Specifically, you must implement the Forward Procedure and the Viterbi algorithm to tell us i) what is the probability of observing this string of words (i.e. what is the probability of this <strong>observed</strong> sequence given your Hidden Markov model) and ii) what is the most probable sequence of part of speech tags for this model? (i.e. what is the most probable <strong>hidden</strong> POS sequence that generated this string?)</p>

<p>For this assignment you will assume only a very limited fragment of a HMM that could do POS tagging for English: you will be limited to three words (<em>time</em>, <em>flies</em> and <em>quickly</em>) and three part of speech tags (<strong><em>N</em></strong>oun, <strong><em>V</em></strong>erb and adve<strong><em>R</em></strong>b). This problem is not totally artificial however: you'll be using an HMM that is estimated from the Brown corpus. Here are the emission probabilities (<strong>B</strong> matrix) of the three words conditioned on the three underlying POS states:</p>

<table>
<thead>
<tr>
<th>. </th>
<th> time </th>
<th> flies </th>
<th> quickly</th>
</tr>
</thead>
<tbody>
<tr>
<td>N </td>
<td> 0.98 </td>
<td> 0.015 </td>
<td> 0.005</td>
</tr>
<tr>
<td>V </td>
<td> 0.33 </td>
<td> 0.64 </td>
<td> 0.03</td>
</tr>
<tr>
<td>R </td>
<td> 0.01 </td>
<td> 0.01 </td>
<td> 0.98</td>
</tr>
</tbody>
</table>


<p>These estimates were calculated using Laplace smoothing, which yields non-zero estimates for the probabilities of each word from each POS. Now, for your estimate of the transitional probabilities between each POS tag, the <strong>A</strong> matrix. As before, estimated from the Brown corpus with a little bit of Laplace smoothing and post-hoc fiddling:</p>

<table>
<thead>
<tr>
<th>.  </th>
<th> N </th>
<th> V </th>
<th> R</th>
</tr>
</thead>
<tbody>
<tr>
<td>N </td>
<td> 0.64 </td>
<td> 0.28 </td>
<td> 0.08</td>
</tr>
<tr>
<td>V </td>
<td> 0.67 </td>
<td> 0.20 </td>
<td> 0.13</td>
</tr>
<tr>
<td>R </td>
<td> 0.19 </td>
<td> 0.70 </td>
<td> 0.11</td>
</tr>
</tbody>
</table>


<p>Finally, your $$$\pi$$$ vector, the starting probabilities for each POS tag:</p>

<table>
<thead>
<tr>
<th>N </th>
<th> V </th>
<th> R</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.63 </td>
<td> 0.27 </td>
<td> 0.10</td>
</tr>
</tbody>
</table>


<p>OK: that's your HMM. Now, onto the algorithms!</p>

<h3>Part 1: The Forward Procedure</h3>

<p>For part 1 of this assignment, we would like you to write a function that uses the Forward Procedure to calculate the probability of any sequence of words given the HMM above. You may implement the Forward Procedure as presented in class any way you see fit. Here is rough, but recommended pseudocode for a Forward Procedure function:</p>

<pre><code>function: forwardProcedure(test_sequence,A,B,pi)
    create table to store results
    for tag in the tag set:
        the first forward probability is pi[tag]
    for all words in test_sequence:
        for all the tags j in the tag set:
            for all the tags i in the tag set:
                the current forward probability for the tag j is sum over all tags i of:
                    previous forward probability of tag i *
                    transition probability from tag i to tag j *
                    emission probability of current word from tag i

    sum forward probabilities over last column in table, and return probability
</code></pre>

<p><strong>Deliverable</strong>: In your <code>.py</code> file for this assignment, provide us with a function <code>forwardProcedure</code> that takes the three parameters of an HMM and a sequence of observations, and returns the probability of that sequence under that HMM. Run your Forward Procedure function on the string 'time flies quickly', and have your <code>.py</code> file print the result on the command line.</p>

<h3>Part 2: The Viterbi Algorithm</h3>

<p>For part 2 of this assignment, we would like you to write a function that uses the Viterbi Algorithm to determine the correct part of speech classification for a sequence of words given the HMM above. You may implement the Viterbi Algorithm as presented in class any way you see fit. Here is rough, but recommended pseudocode however (<strong>hint</strong>: try to use as much of the code from your forward procedure function as possible!)</p>

<pre><code>function: viterbiAlgorithm(test_sequence,A,B,pi)
    create table to store deltas
    create table to store psis
    for tags in the tag set:
        the first delta probability is pi[tag]
        the first psi value is simply '-' (no value)
    for all words in test_sequence:
        for all the tags j in the tag set:
            for all the tags i in the tag set:
                calculate and store:
                    previous delta for tag i *
                    transition probability from tag i to tag j *
                    emission probability of current word from tag i
            current delta value for tag j is the max delta calculated on previous step
            current psi value for tag j is the the tag that yields the max delta        
        read best POS sequence off of psi values and return
</code></pre>

<p><strong>Deliverable</strong>: In your <code>.py</code> file for this assignment, provide us with a function <code>viterbiAlgorithm</code> that takes the three parameters of an HMM and a sequence of observations, and returns the most likely POS sequence under that HMM. Run your Viterbi Algorithm function on the string 'time flies quickly', and have your <code>.py</code> file print the result on the command line.</p>

<p>In the comments of your <code>.py</code> file, address the following questions. Q1: What is the probability of the sequence 'time flies quickly'? How many tag sequences contribute to this probability (i.e. how many non-zero ways of tagging 'time flies quickly' are there according to the HMM? Q2: What is the best tag sequence for 'time flies quickly'? What meaning does this sequence correspond to? Q3: What's the probability of 'quickly time flies'? What parameters could you change to make 'quickly time flies' more likely than 'time flies quickly'? Be specific! Q4: Modify matrix B to add a new word 'swat' to the lexicon. Assume that 'swat' can *only* be a verb, and make sure your matrix defines proper probability distributions. Set the probabilities so that the most likely sequence for 'swat flies quickly' is 'V N R' (hint: you may need to change probabilities in multiple rows!). Run your script on this sentence with your modified B matrix to demonstrate that it has the correct behavior.
</body>
</html>